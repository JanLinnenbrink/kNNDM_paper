#' Sample simulation: virtual species.
#' @details
#' Simulates a series of sampling points for the simulation.
#' Two more extreme sampling strategies to increase the range of different WS.dist.
#' @param nsamples Integer. Number of samples to simulate.
#' @param dsamples Character. Spatial distribution of the samples. 7 are
#' possible: "sregular", "wregular", "random", "wclust","sclust","vclust","eclust".
#' @param sarea sf/sfc polygon where samples will be simulated.
sim2_samples <- function(nsamples, dsamples, sarea){
if(dsamples=="sregular"){
simpoints <- jitterreg_sample(sarea, nsamples, 40000)
}else if(dsamples=="wregular"){
simpoints <- jitterreg_sample(sarea, nsamples, 80000)
}else if(dsamples=="random"){
simpoints <- st_sample(sarea, nsamples)
}else if(dsamples=="wclust"){
simpoints <- clustered_sample(sarea, nsamples, 25, 80000)
}else if(dsamples=="sclust"){
simpoints <- clustered_sample(sarea, nsamples, 10, 80000)
}else if(dsamples=="vclust"){
simpoints <- clustered_sample(sarea, nsamples, 10, 40000)
}else if(dsamples=="eclust"){
simpoints <- clustered_sample(sarea, nsamples, 5, 40000)
}
simpoints <- st_sf(geometry=simpoints)
simpoints
}
#' Fits a RF model and evaluates it using different kNNDM configurations and sample point distributions.
#' @details
#' Fits a RF model and evaluates it using kNNDM 10-fold CV in different configurations and true errors.
#' @param form String. Model formula.
#' @param kndm_folds list. Indices for kndm CV.
#' @param pgrid Data frame. Parameter grid of the model.
#' @param traindf Data frame. Training data to fit the model.
#' @param surfdf Data frame. Surface data.
fitval_rf_species <- function(form,
kndm_folds,
pgrid, traindf,
surfdf) {
# Validate with random CV and compute metrics
r_cntrl <- trainControl(method="CV", savePredictions=TRUE)
rand_mod <- train(form, data=traindf, method="rf",
trControl=r_cntrl, tuneGrid=pgrid, ntree=100)
rand_stats <- rand_mod$pred %>%
summarise(RMSE = sqrt(mean((obs-pred)^2)),
MAE = mean(abs(obs-pred)),
R2 = cor(obs, pred)^2)
names(rand_stats) <- paste0(names(rand_stats), "_rand")
# Compute CV statistics in surface
surfdf$preds <- predict(rand_mod, newdata=surfdf)
surf_stats <- surfdf %>%
summarise(RMSE = sqrt(mean((outcome-preds)^2)),
MAE = mean(abs(outcome-preds)),
R2 = cor(outcome, preds)^2)
names(surf_stats) <- paste0(names(surf_stats), "_surf")
# Validate with knndm
if (class(kndm_folds)=="list") {
kndm_stats <- lapply(kndm_folds, function(x) {
fdf <- data.frame(f=x)
ctrl <- CAST::CreateSpacetimeFolds(fdf, spacevar=1, k = max(fdf))
kndm_ctrl <- trainControl(method="cv",
index=ctrl$index,
indexOut=ctrl$indexOut,
savePredictions=TRUE)
kndm_out_mod <- suppressWarnings( # train() can't compute R2
train(form, data=traindf, method="rf",
trControl=kndm_ctrl, tuneGrid=pgrid, ntree=100))
kndm_stats <- kndm_out_mod$pred %>%
summarise(RMSE = sqrt(mean((obs-pred)^2)),
MAE = mean(abs(obs-pred)),
R2 = cor(obs, pred)^2)
names(kndm_stats) <- paste0(names(kndm_stats), "_kndm")
kndm_stats
})
kndm_stats <- do.call(rbind, kndm_stats)
} else {
fdf <- data.frame(f=kndm_folds)
ctrl <- CAST::CreateSpacetimeFolds(fdf, spacevar=1, k = max(fdf))
kndm_ctrl <- trainControl(method="cv",
index=ctrl$index,
indexOut=ctrl$indexOut,
savePredictions=TRUE)
kndm_out_mod <- suppressWarnings( # train() can't compute R2
train(form, data=traindf, method="rf",
trControl=kndm_ctrl, tuneGrid=pgrid, ntree=100))
kndm_stats <- kndm_out_mod$pred %>%
summarise(RMSE = sqrt(mean((obs-pred)^2)),
MAE = mean(abs(obs-pred)),
R2 = cor(obs, pred)^2)
names(kndm_stats) <- paste0(names(kndm_stats), "_kndm")
kndm_stats
}
kndm_stats_diff <- data.frame(
RMSE_surf = surf_stats$RMSE_surf, R2_surf = surf_stats$R2_surf, MAE_surf = surf_stats$MAE_surf,
RMSE_kndm = kndm_stats$RMSE_kndm, R2_kndm = kndm_stats$R2_kndm, MAE_kndm = kndm_stats$MAE_kndm)
kndm_stats_diff
}
rgrid <- st_read("data/data/species_vdata.gpkg", layer="sampling_polygon")
rgrid <- st_read("data/species_vdata.gpkg", layer="sampling_polygon")
rgrid <- st_read("data/species_vdata.gpkg", layer="landscape_grid")
sampling_area <- st_read("data/species_vdata.gpkg", layer="sampling_polygon")
rstack <- rast("data/species_stack.grd")
ppoints <- st_sample(sampling_area, 1000, type="regular")
sample_dist=c("sregular", "wregular", "random", "wclust","sclust","vclust","eclust")
ppoints <- st_sample(sampling_area, 1000, type="regular")
# Initiate results object and fixed information for all models
res <- data.frame()
grid_data <- as.data.frame(terra::extract(rstack, terra::vect(rgrid)))
form <- as.formula(paste0("outcome~", paste0("bio", 1:19, collapse="+")))
pgrid <- data.frame(mtry=6)
i <- 0
# Start sampling loop
for(dist_it in sample_dist){
i=i+1
# Simulate sampling points according to parameters and constraints
train_points <- sim2_samples(100, dist_it, sampling_area)
ppoints <- sf::st_transform(ppoints, sf::st_crs(train_points))
# Get training and surface data for modelling and validation
train_data <- terra::extract(rstack, train_points)
# Estimate outcome range
train_points$outcome <- train_data$outcome
# kndm
folds_kndm <- knndmW(train_points, ppoints = ppoints, clustering = "kmeans", k=10, maxp=0.5)
#### Model fitting and validation
mod <- fitval_rf_species(form,
folds_kndm$clusters,
pgrid, train_data,
grid_data)
mod_all <- cbind(mod, data.frame(WS=folds_kndm$W))
# Store results of the iteration
res_it <- cbind(data.frame(dsample=dist_it, stringsAsFactors = FALSE),
mod_all)
res <- bind_rows(res, res_it)
}
row.names(res) <- NULL
res
# We're done
stopCluster(cl)
rm("cl")
i <- 0
# Start sampling loop
for(dist_it in sample_dist){
i=i+1
# Simulate sampling points according to parameters and constraints
train_points <- sim2_samples(100, dist_it, sampling_area)
ppoints <- sf::st_transform(ppoints, sf::st_crs(train_points))
# Get training and surface data for modelling and validation
train_data <- terra::extract(rstack, train_points)
# Estimate outcome range
train_points$outcome <- train_data$outcome
# kndm
folds_kndm <- knndmW(train_points, ppoints = ppoints, clustering = "kmeans", k=10, maxp=0.5)
#### Model fitting and validation
mod <- fitval_rf_species(form,
folds_kndm$clusters,
pgrid, train_data,
grid_data)
mod_all <- cbind(mod, data.frame(WS=folds_kndm$W))
# Store results of the iteration
res_it <- cbind(data.frame(dsample=dist_it, stringsAsFactors = FALSE),
mod_all)
res <- bind_rows(res, res_it)
}
# Libraries and utils ----
library("tidyverse")
library("raster")
library("terra")
library("CAST")
library("sf")
library("caret")
library("gstat")
library("virtualspecies")
library("parallel")
library("doParallel")
library("pbapply")
source("code/sim_utils.R")
source("code/knndm_W.R")
nsim <- 1
pboptions(type = "timer")
# Read data
spoly <- st_read(dsn="data/species_vdata.gpkg", layer="sampling_polygon")
wclim <- rast("data/species_stack.grd")
wgrid <- st_read(dsn="data/species_vdata.gpkg", layer="landscape_grid")
# Prepare parallelization
print(paste0("Process started with ", 11, " cores."))
cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
# Launch simulation
set.seed(1234)
sims <- pbreplicate(nsim, sim_species(wgrid, wclim, spoly), simplify=FALSE)
Q
nrow(sims)
sims
do.call(rbind,sim)
do.call(rbind,sims)
nrow(do.call(rbind,sims))
# Launch simulation
set.seed(1234)
sims <- pbreplicate(nsim, sim_species(wgrid, wclim, spoly), simplify=FALSE)
#-----------------------------------------------------------#
#             Simulation analysis: virtual species          #
#-----------------------------------------------------------#
#.libPaths("/home/j/jlinnenb/r_packages/")
library("parallel")
library("doParallel")
library("pbapply")
# Load utils, functions, and define number of iterations
source("code/sim_functions_W.R")
nsim <- 1
pboptions(type = "timer")
# Read data
spoly <- st_read(dsn="data/species_vdata.gpkg", layer="sampling_polygon")
wclim <- rast("data/species_stack.grd")
wgrid <- st_read(dsn="data/species_vdata.gpkg", layer="landscape_grid")
# Prepare parallelization
print(paste0("Process started with ", 11, " cores."))
cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
# Launch simulation
set.seed(1234)
sims <- pbreplicate(nsim, sim_species(wgrid, wclim, spoly), simplify=FALSE)
sims
nrow(sims[[1]])
490/7
s <- sims[[1]]
s[s$dsample=="wregular"]
s[s$dsample=="wregular",]
nrow(s[s$dsample=="wregular",])
tapply(s$dsample, s, nrow)
tapply(s$dsample, s$dsample, length)
rgrid <- st_read("data/species_vdata.gpkg", layer="landscape_grid")
sampling_area <- st_read("data/species_vdata.gpkg", layer="sampling_polygon")
rstack <- rast("data/species_stack.grd")
sample_dist=c("sregular", "wregular", "random", "wclust","sclust","vclust","eclust")
ppoints <- st_sample(sampling_area, 1000, type="regular")
# Initiate results object and fixed information for all models
res <- data.frame()
grid_data <- as.data.frame(terra::extract(rstack, terra::vect(rgrid)))
form <- as.formula(paste0("outcome~", paste0("bio", 1:19, collapse="+")))
pgrid <- data.frame(mtry=6)
i <- 0
dist_it <- "random"
i=i+1
# Simulate sampling points according to parameters and constraints
train_points <- sim2_samples(100, dist_it, sampling_area)
ppoints <- sf::st_transform(ppoints, sf::st_crs(train_points))
# Get training and surface data for modelling and validation
train_data <- terra::extract(rstack, train_points)
# Estimate outcome range
train_points$outcome <- train_data$outcome
# kndm
folds_kndm <- knndmW(train_points, ppoints = ppoints, clustering = "kmeans", k=10, maxp=0.5)
folds_kndm
length(folds_kndm)
length(folds_kndm[[1]])
tpoints=train_points; modeldomain = NULL; ppoints = ppoints;
k = 10; maxp = 0.5;
clustering = "kmeans"; linkf = "ward.D2";
samplesize = 1000; sampling = "regular"
# create sample points from modeldomain
if(is.null(ppoints)&!is.null(modeldomain)){
if(!identical(sf::st_crs(tpoints), sf::st_crs(modeldomain))){
stop("tpoints and modeldomain must have the same CRS")
}
message(paste0(samplesize, " prediction points are sampled from the modeldomain"))
ppoints <- sf::st_sample(x = modeldomain, size = samplesize, type = sampling)
sf::st_crs(ppoints) <- sf::st_crs(modeldomain)
}else if(!is.null(ppoints)){
if(!identical(sf::st_crs(tpoints), sf::st_crs(ppoints))){
stop("tpoints and ppoints must have the same CRS")
}
}
# Prior checks
if (!(clustering %in% c("kmeans", "hierarchical"))) {
stop("clustering must be one of `kmeans` or `hierarchical`")
}
if (!(maxp < 1 & maxp > 1/k)) {
stop("maxp must be strictly between 1/k and 1")
}
if (any(class(tpoints) %in% "sfc")) {
tpoints <- sf::st_sf(geom = tpoints)
}
if (any(class(ppoints) %in% "sfc")) {
ppoints <- sf::st_sf(geom = ppoints)
}
if(is.na(sf::st_crs(tpoints))){
warning("Missing CRS in training or prediction points. Assuming projected CRS.")
islonglat <- FALSE
}else{
islonglat <- sf::st_is_longlat(tpoints)
}
if(isTRUE(islonglat) & clustering == "kmeans"){
stop("kmeans works in the Euclidean space and therefore can only handle
projected coordinates. Please use hierarchical clustering or project your data.")
}
# Gj and Gij calculation
tcoords <- sf::st_coordinates(tpoints)[,1:2]
if(isTRUE(islonglat)){
distmat <- sf::st_distance(tpoints)
units(distmat) <- NULL
diag(distmat) <- NA
Gj <- apply(distmat, 1, function(x) min(x, na.rm=TRUE))
Gij <- sf::st_distance(ppoints, tpoints)
units(Gij) <- NULL
Gij <- apply(Gij, 1, min)
}else{
Gj <- c(FNN::knn.dist(tcoords, k = 1))
Gij <- c(FNN::knnx.dist(query = sf::st_coordinates(ppoints)[,1:2],
data = tcoords, k = 1))
}
if(clustering == "hierarchical"){
# For hierarchical clustering we need to compute the full distance matrix,
# but we can integrate geographical distances
if(!isTRUE(islonglat)){
distmat <- sf::st_distance(tpoints)
}
hc <- stats::hclust(d = stats::as.dist(distmat), method = linkf)
}
# Build grid of number of clusters to try - we sample low numbers more intensively
clustgrid <- data.frame(nk = as.integer(round(exp(seq(log(k), log(nrow(tpoints)-2),
length.out = 100)))))
clustgrid
nrow(clustgrid)
clustgrid$W <- NA
clustgrid <- clustgrid[!duplicated(clustgrid$nk),]
clustgroups <- list()
# Compute 1st PC for ordering clusters
pcacoords <- stats::prcomp(tcoords, center = TRUE, scale. = FALSE, rank = 1)
# We test each number of clusters
for(nk in clustgrid$nk){
# Create nk clusters
if(clustering == "hierarchical"){
clust_nk <- stats::cutree(hc, k=nk)
}else if(clustering == "kmeans"){
clust_nk <- stats::kmeans(tcoords, nk)$cluster
}
tabclust <- as.data.frame(table(clust_nk))
tabclust$clust_k <- NA
# compute cluster centroids and apply PC loadings to shuffle along the 1st dimension
centr_tpoints <- sapply(tabclust$clust_nk, function(x){
centrpca <- matrix(apply(tcoords[clust_nk %in% x, , drop=FALSE], 2, mean), nrow = 1)
colnames(centrpca) <- colnames(tcoords)
return(predict(pcacoords, centrpca))
})
tabclust$centrpca <- centr_tpoints
tabclust <- tabclust[order(tabclust$centrpca),]
# We don't merge big clusters
clust_i <- 1
for(i in 1:nrow(tabclust)){
if(tabclust$Freq[i] >= nrow(tpoints)/k){
tabclust$clust_k[i] <- clust_i
clust_i <- clust_i + 1
}
}
rm("clust_i")
# And we merge the remaining into k groups
clust_i <- setdiff(1:k, unique(tabclust$clust_k))
tabclust$clust_k[is.na(tabclust$clust_k)] <- rep(clust_i, ceiling(nk/length(clust_i)))[1:sum(is.na(tabclust$clust_k))]
tabclust2 <- data.frame(ID = 1:length(clust_nk), clust_nk = clust_nk)
tabclust2 <- merge(tabclust2, tabclust, by = "clust_nk")
tabclust2 <- tabclust2[order(tabclust2$ID),]
clust_k <- tabclust2$clust_k
# Compute W statistic if not exceeding maxp
if(!any(table(clust_k)/length(clust_k)>maxp)){
if(isTRUE(islonglat)){
Gjstar_i <- distclust_geo(distmat, clust_k)
}else{
Gjstar_i <- distclust_proj(tcoords, clust_k)
}
clustgrid$W[clustgrid$nk==nk] <- twosamples::wass_stat(Gjstar_i, Gij)
clustgroups[[paste0("nk", nk)]] <- clust_k
}
}
clustgroups
length(clustgroups)
nrow(tabclust2)
clust_k
length(clust_k)
clust_k
!any(table(clust_k)/length(clust_k)>maxp)
table(clust_k)/length(clust_k)
maxp
any(table(clust_k)/length(clust_k)>maxp)
length(clust_k)
Gjstar_i
nrow(clustgrid)
clustgrid$W[clustgrid$nk==nk] <- twosamples::wass_stat(Gjstar_i, Gij)
clustgrid
nrow(clustgrid)
tabclust2
clust_k
clust_k
table(tabclust2)
table(clust_k)
tabclust2
nrow(tabclust2)
unique(tabclust2$Freq)
table(tabclust2$Freq)
tabclust
tabclust$Freq[i]
# Create nk clusters
if(clustering == "hierarchical"){
clust_nk <- stats::cutree(hc, k=nk)
}else if(clustering == "kmeans"){
clust_nk <- stats::kmeans(tcoords, nk)$cluster
}
tabclust <- as.data.frame(table(clust_nk))
clust_nk
stats::kmeans(tcoords, nk)$cluster
nk
clustgrid$nk
cor_res <- read.csv("results/sim_res_W.csv")
nrow(cor_res)
nrow(cor_res)/7
70*100
70*100*7
library("ggplot2")
library("cowplot")
cor_res <- read.csv("results/sim_res_W.csv")
cor_diff <- data.frame(rmse_diff = cor_res$RMSE_kndm - cor_res$RMSE_surf,
r2_diff = cor_res$R2_kndm - cor_res$R2_surf,
mae_diff = cor_res$MAE_kndm - cor_res$MAE_surf,
ws = cor_res$WS,
dsample = cor_res$dsample)
m <- 0.5
b.size <- 20
lm_rmse <- lm(abs(rmse_diff)~ws, cor_diff)
r2_rmse <- round(summary(lm_rmse)$r.squared,2)
pred_rmse <- predict(lm_rmse, cor_diff)
lm_mae <- lm(abs(mae_diff)~ws, cor_diff)
r2_mae <- round(summary(lm_mae)$r.squared,2)
pred_mae <- predict(lm_mae, cor_diff)
lm_r2 <- lm(abs(r2_diff)~ws, cor_diff)
r2_r2 <- round(summary(lm_r2)$r.squared,2)
pred_r2 <- predict(lm_r2, cor_diff)
print(paste("Rsquared for Rsquared:", r2_r2, ";",
"Rsquared for MAE:", r2_mae, ";",
"Rsquared for RMSE:", r2_rmse))
rmse <- ggplot(data=cor_diff, aes(x=ws,y=abs(rmse_diff))) +
geom_bin_2d(bins=30) +
geom_line(aes(y=pred_rmse), col="black", linewidth=1.2) +
scale_fill_viridis_b(trans="log10") +
scale_x_continuous(n.breaks = 3,labels = function(x) format(x, scientific = FALSE)) +
ylab(expression(abs(CV - true~RMSE))) +
xlab("W") +
theme_bw(base_size=b.size) +
theme(aspect.ratio=1, legend.position = NaN,
plot.margin = unit(unit(rep(m,4), "cm")))
mae <- ggplot(data=cor_diff, aes(x=ws,y=abs(mae_diff))) +
geom_bin_2d(bins=30) +
geom_line(aes(y=pred_mae), col="black", linewidth=1.2) +
scale_fill_viridis_b(trans="log10") +
scale_x_continuous(n.breaks = 3,labels = function(x) format(x, scientific = FALSE)) +
ylab(expression(abs(CV - true~MAE))) +
xlab("W") +
theme_bw(base_size=b.size) +
theme(aspect.ratio=1, legend.position = NaN,
plot.margin = unit(rep(m,4), "cm"))
r2 <- ggplot(data=cor_diff, aes(x=ws,y=abs(r2_diff))) +
geom_bin_2d(bins=30) +
geom_line(aes(y=pred_r2), col="black", linewidth=1.2) +
scale_fill_viridis_b(trans="log10") +
scale_x_continuous(n.breaks = 3,labels = function(x) format(x, scientific = FALSE)) +
ylab(expression(abs(CV - true~R^2))) +
xlab("W") +
theme_bw(base_size=b.size) +
theme(aspect.ratio=1, legend.position = NaN,
plot.margin = unit(unit(rep(m,4), "cm")))
legend_bottom <- get_legend(rmse +
guides(color = guide_legend(nrow = 1)) +
theme(legend.position = "bottom",
legend.key.width  = unit(1.5, "cm"),
legend.key.height  = unit(0.5, "cm"),
plot.margin = unit(c(0, 0, 0, 0), "cm")))
top_row <- plot_grid(rmse, r2, mae, nrow=1, align="hv")
c <- plot_grid(top_row, NULL, legend_bottom, NULL, nrow=4,
rel_heights = c(1,-0.35,1,-0.4), rel_widths = c(1,1,5,1))
#ggsave("figures/4_results_W_err.pdf",c, height=5, width=12)
c
rgrid
nrow(rgrid)
#-----------------------------------------------------------#
#             Simulation analysis: virtual species          #
#-----------------------------------------------------------#
#.libPaths("/home/j/jlinnenb/r_packages/")
library("parallel")
library("doParallel")
library("pbapply")
setwd("C:/git/kNNDM_paper/")
#-----------------------------------------------------------#
#             Simulation analysis: virtual species          #
#-----------------------------------------------------------#
#.libPaths("/home/j/jlinnenb/r_packages/")
library("parallel")
library("doParallel")
library("pbapply")
# Load utils, functions, and define number of iterations
source("code/sim_functions.R")
nsim <- 1
pboptions(type = "timer")
# Read data
spoly <- st_read(dsn="data/species_vdata.gpkg", layer="sampling_polygon")
wclim <- rast("data/species_stack.grd")
wgrid <- st_read(dsn="data/species_vdata.gpkg", layer="landscape_grid")
# Prepare parallelization
print(paste0("Process started with ", 11, " cores."))
cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
# Launch simulation
set.seed(1234)
sims <- pbreplicate(nsim, sim_species(wgrid, wclim, spoly), simplify=FALSE)
sims
